---
layout: page
title:  "Random Intercept Cross-Lagged Panel Model"
subtitle: ""
date:   2024-09-19 01:45:01 +0530
categories: ["Longitudinal Analysis"]
---


Due to the abundant online resources available for the RI-CLPM, the guidance they provide far exceeds the scope of my tutorial. Therefore, before starting, I recommend that you first read the following papers:
- Muthén, B., Asparouhov, T., & Witkiewitz, K. (2024). Cross-lagged panel modeling with binary and ordinal outcomes. Advance online publication. DOI: 10.1037/met0000701.
- Mulder, J.D. & Hamaker, E.L. (2020). Three extensions of the Random Intercept Cross-Lagged Panel Model. Structural Equation Modeling: A Multidisciplinary Journal, DOI: 10.1080/10705511.2020.1784738
- Hamaker, E. L., Kuiper, R. M., & Grasman, R. P. P. P. (2015). A critique of the cross-lagged panel model. Psychological Methods, 20(1), 102-116. DOI: 10.1037/a0038889

Here is an excellent website, thanks to Jeroen D. Mulder and Ellen L. Hamaker for creating it! It contains the most comprehensive RI-CLPM code, including various extended models:
[https://jeroendmulder.github.io/RI-CLPM/](https://jeroendmulder.github.io/RI-CLPM/)
<br>Additionally, this website provides everything you need before conducting an analysis with RI-CLPM, including videos, papers, and other useful resources:
[https://www.statmodel.com/RI-CLPM.shtml](https://www.statmodel.com/RI-CLPM.shtml)

<h2><strong>Why Do We Need the RI-CLPM Model?</strong></h2>
As I mentioned in my previous blog, the advantage of the CLPM lies in its ability to examine the predictive effect of one variable on another, while controlling for the correlation between variables at the same time point and the stability of variables across time. However, the autoregressive method in CLPM only controls for temporal stability and does not account for the possibility that stability in a variable may take different forms. That is, every individual changes around the same mean value for the same variable, with no mean differences between individuals. Longitudinal data is inherently multilevel data, with the sources of variance in variables naturally categorized into between-person level and within-person level. However, CLPM conflates the effects at these two different levels.

Thus, based on CLPM, Hamaker et al. (2015) introduced the RI-CLPM, which differentiates between the between-person level and the within-person level. By using structural equation modeling, the model introduces a random intercept latent variable that represents individual differences that do not change over time. This allows for the observation that individuals no longer fluctuate around a common sample mean but rather around their own individual intercepts. At the within-person level, the basic ideas of CLPM are preserved. The RI-CLPM is similar to experimental manipulation: after controlling for individual trait differences, it examines how changes in one variable at one time point “lead” to changes in another variable at the next time point.

<h2><strong>What Can RI-CLPM Tell Us? Or, What Can It Help Us Understand?</strong></h2>

1. The between-person level can tell us "who is at high risk for a certain variable" and "who may need intervention."
2. The within-person level can help us understand "what interventions can reduce an individual’s risk for a certain variable."

At the between-person level, it may be useful to know how adolescents are situated within the group and which individuals are more likely to have higher or lower levels of psychological variables than their peers. Within-person modeling should be considered to explore development at the individual level (Hudson et al., 2019). Moreover, within-person associations may help identify modifiable targets for intervention (while between-person associations help detect who needs an intervention) (Masselink et al., 2018).

<h2><strong>Basic RI-CLPM</strong></h2>
Here, I’ve directly copied content from Mulder and Hamaker (2021), and you can also check their paper for further details.
To fit an RI-CLPM, we need to decompose the observed scores into three components: grand means, stable between components, and fluctuating within components. The first component is the grand means, which represent the mean values across all units at each occasion. The second component, the between components, are the random intercepts, which capture an individual’s time-invariant deviation from the grand means, reflecting stable differences between individuals. The third component, the within components, are the deviations of an individual’s observed measurements from their expected scores based on the grand means and random intercepts (Mulder & Hamaker, 2021).

**Autoregressive Effects** represent within-person carry-over effects, also known as inertia. The autoregressive path coefficients indicate how the changes in one variable at one time point “lead” to changes in the same variable at the next time point.
The autoregressive effects (i.e., αt from WSi t-1 to WSit and δt from WAi t-1 to WAit) represent within-person carry-over effects. If αt is positive, this implies that an individual who experiences elevated sleep problems relative to their own expected score is likely to experience elevated sleep problems again at the next occasion (Mulder & Hamaker, 2021). These within-person autoregressive effects are sometimes referred to as inertia (i.e., the tendency to not move; see Suls et al., 1998) (Mulder & Hamaker, 2021).

**Cross-Lagged Effects** represent how changes or fluctuations in one variable at one time point “lead” to changes or fluctuations in another variable at the next time point.
The cross-lagged effects in the model represent the spill-over of the state in one domain into the state of another domain. Here, βt represents the effect from WSi t-1 to WAit and γt represents the effect from WAi t-1 to WSit. A positive βt implies that a positive (or negative) deviation from an individual’s expected level of sleep problems will likely be followed by a positive (or negative) deviation in the individual’s expected level of anxiety at the next occasion, in the same direction (Mulder & Hamaker, 2021).

**Random Intercepts**: If the variance of a random intercept for a variable is significant, it indicates there are notable between-person differences in that variable. A positive correlation between random intercepts of different variables suggests that individuals who score high on one variable tend to score high on another variable. 
We find that both random intercepts have significant variance, indicating stable, trait-like differences between individuals on sleep problems and anxiety (Mulder & Hamaker, 2021). If, in contrast to our findings here, the variance of a random intercept is not significantly different from zero, it suggests that there are minimal or no stable between-person differences, and each individual fluctuates around the same grand mean over time (Mulder & Hamaker, 2021). We also find a significant positive covariance between the random intercepts (r = .59, SE = .050), suggesting that individuals who have more sleep problems are generally also more anxious (Mulder & Hamaker, 2021).

<h2><strong>How to Build an RI-CLPM Model in Mplus</strong></h2>
As I mentioned earlier, Jeroen D. Mulder and Ellen L. Hamaker’s website offers comprehensive code resources, which you can directly copy and use: [https://jeroendmulder.github.io/RI-CLPM/](https://jeroendmulder.github.io/RI-CLPM/)

<h2><strong>Basic RI-CLPM Implementation in R</strong></h2>
I want to demonstrate how to build a basic RI-CLPM model using R, as it’s often more convenient and faster to work with R. I found a longitudinal dataset from a survey in China. It has four time points and two continuous variables. You don't need to worry about the specifics of the data because it’s just for practice.

```r
# Install and load the lavaan package
# install.packages("lavaan")
library(lavaan)

# Load the dataset
data = read.table("ex9.36.dat", col.names = c("x1", "x2", "x3", "x4", "y1", "y2", "y3", "y4", 'subject'))

# Define the model
model = '  
  # Define regression paths (cross-lagged and autoregressive)
  x2 + y2 ~ x1 + y1
  x3 + y3 ~ x2 + y2
  x4 + y4 ~ x3 + y3
  # Define correlations between variables
  x1 ~~ y1
  x2 ~~ y2
  x3 ~~ y3
  x4 ~~ y4'

# Estimate the model
fit = sem(model, data = data)

# Check the model fit statistics
summary(fit, fit.measures = TRUE)

# Draw the path diagram (many methods available)
# The following method produces a diagram closer to Mplus output
library(tidySEM)
graph_sem(fit, layout = get_layout("x1", "x2", "x3", "x4", "y1", "y2", "y3", "y4", rows = 2))
```

<h2><strong>Notes</strong></h2>
1. x1 represents the first measurement of variable x, y1 represents the first measurement of variable y, and so on.
2. When defining regression paths, you need to include both autoregressive and cross-lagged effects.
3. Don’t forget to define correlations between variables.
4. `graph_sem` produces a diagram that resembles Mplus output. The `get_layout` parameter is used to set the positions of the variables in the diagram.
That concludes the content of this blog. 
<br>If you have any questions, feel free to email me.
